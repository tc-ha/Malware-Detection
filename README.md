# <div align=center>Malware Detection</div>



### <div align=center>2021.06 ~ 2021.07</div>


<div align=center>Malware Detection Using Machine Learning</div>


![alt](/images/malware.png)


## Table of Contents


- [About The Project](#About-The-Project)
- [Dataset](#Dataset)
- [License](#License)
- [Contact](#Contact)



## About The Project
In June and July of 2021, I crated a machine learning model over the course of project submissions for Information Security class. the model can detect, given an featurized PE file, whether the given data is malware or not. 

Note that, To prevent misuse of malicious code, I have not made the dataset publicly available.

## Dataset
source: VirusShare.com


## License


Distributed under MIT License. See <code>License</code>



## Contact



Taechan Ha - hataeck@gmail.com

Project Link: https://github.com/taechanha/

## Methodology

1. PE Header Extraction
Extract DOSheader, Opticalheader, and PEheader from PE files through the ClaMP open source script. PEheader contains information about the overall program. As shown in the picture below, files such as exe in Windows are PE files, consisting of DOSheader, PEheader, opticalheader, data directories, sectionstable, code, imports, and data. We extracted the header part as a feature using the ClaMP open source script here.
![alt](/images/PE-header.png)

Below is part of the ClaMP open source script. The DOS header and Optical header seen above are saved as a list. Windows PE files define DOSheader, Opticalheader, etc. as structures, and e_cblp, e_cp, and e_cparhdr are designated as fields of structures. Name the corresponding fields as a list so that the values of each field can be extracted.

![alt](/images/PE-header2.png)

Result of The Extraction
From the picture below, it can be seen that the field values of the DOSHEADER of PE files such as e_cblp, e_cp, and e_cparhdr were extracted.
![alt](/images/PE-result.png)

2. N-grams Extraction
Extract 4 with four - gram from a script .. open source capstone
N gram code section located in the assembly code patterns through feature information about the actual programs and capabilities to configure the datasets.
![alt](/images/ngrams.png)

N mov, such as pictures of the - gram cx, said an assembly of codes, such as count the time, two, mov, 2, mov, 2 - 2, 1 - {mov, 3} behind gram gram, such as {mov mov, 2} opcode and store a corresponding number.
![alt](/images/ngram-ex.png)

It's part of Capstone open source script. You can see files being retrieved one by one from Malware and Normal datasets to obtain opcode, calculate 4-gram, and save them in grams.
![alt](/images/ngramscript.png)

Result of The Extraction
Since 4-gram has been extracted, if you look at the column, you can see that four opcodes are listed, such as Decmov decmov. Each file has its corresponding number saved. For example, the number of decmov decmovs in a file with an MD5 value of 372a8c* is 48.
![alt](/images/ngramcsv.png)

3. Convert Binary Code to Image
Convert binary data to image for use as input data on CNN. Below is the code for the conversion, and the file is retrieved and reshape to specify it all to the same size, and the image is saved through the Image function of the PIL library.
![alt](/images/convert.png)

Result of the conversion
![alt](/images/convertex.png)

4. ML/DL Model used
- Random Forest: 
- Light Gradient Boost Machine
- ResNet16

5. Voting Algorithm
Afterwards, to extract feature importance through Random Forest's feature_importances_, and to finally determine how to configure the dataset, we compared the performance in a variety of cases, including Ngram, packer_type feature addition, and how many of the features will be used.
![alt](/images/rffeature.png)

ResNet has been trained for more than 100 epochs since then, but there is no change in accuracy and the peak dataset extracted from the top 63 features is much lower than that of machine learning algorithms, so ResNet was not used for the final voting algorithm.
![alt](/images/voting.png)

6. Final result:
- CNN accuracy: 84%.
- Random Forest accuracy: 96.14%.
- Light Gradient Boost Machine Accuracy: 95.92%.
- Voting Algorithm Accuracy: 96.75%.
